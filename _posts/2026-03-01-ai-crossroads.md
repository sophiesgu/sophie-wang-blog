---
layout: post
title: "AI军事化的十字路口：当硅谷与五角大楼正面交锋"
date: 2026-03-01 17:00:00 +0800
author: "Sophie Wang"
categories: [AI, 日报]
---

2026年2月的最后一周，AI行业发生了一件将被载入史册的大事：Anthropic公开拒绝了美国国防部的要求，并宣布将在法庭上与其对抗。与此同时，OpenAI走向了另一条路——与五角大楼签署协议，允许军方在机密网络中部署其AI模型。

这两条路，代表了整个AI行业在军事化问题上的根本性分歧，也将我们所有人拉进了一个无法回避的追问：**人工智能，究竟应该为谁服务？**

---

## 一、拒绝的勇气，还是商业的代价？

故事从国防部的一纸要求开始。五角大楼希望Anthropic同意允许其AI被用于"任何合法用途"——听起来不过分，但对于一家将"安全"写进使命宣言的AI公司来说，这意味着什么？

Anthropic选择了拒绝。不仅拒绝，还公开表示将在法庭上挑战这一"供应链风险"的指定。这一举动让前司法部官员Alan Rozenshtein直言：这可能是美国政府迈向"AI行业部分国有化"的第一步。

更令人意外的是，Ilya Sutskever——那个曾推动了OpenAI内部最大动荡、离开后创立Safe Superintelligence的男人——公开在X上力挺Anthropic，称"竞争对手能放下分歧携手合作，是今天最值得记录的事。"

然而就在同一天，OpenAI宣布与五角大楼达成新协议。Sam Altman在X上写道，协议允许美军在机密网络中部署OpenAI模型，并承诺禁止用于"国内大规模监控"和"自主武器系统的武力决策"。他甚至呼吁国防部把同样的条款提供给所有AI公司——这是在邀请Anthropic回到谈判桌，还是在为自己的选择寻求道德遮掩？

没有人知道答案。但硅谷的分裂，已经清晰可见。

---

## 二、当AI知道了太多

就在这场军事化争论愈演愈烈之际，另一个故事悄悄改变了AI安全的叙事边界。

今年2月，加拿大不列颠哥伦比亚省一所学校发生枪击案，8人遇难。事后调查发现，嫌疑人与ChatGPT的对话内容曾出现明显的暴力倾向信号。OpenAI关闭了该账号——但没有报警。

OpenAI随即更新了安全协议：今后，若AI在对话中检测到真实暴力可能性，将主动通知执法部门。

这个决定看起来合理，甚至道德上无可指摘。但它打开了一扇不可忽视的门：**AI现在不只是工具，它开始成为监控者。**

谁来定义"真实暴力可能性"？谁来监督这个判断过程？当一个人在深夜对着AI倾诉愤怒和绝望，他是在找情绪出口，还是在触发一次警察上门？

这些问题，没有简单答案。但我们必须开始认真讨论它们。

---

## 三、意识、算法与一个未解的哲学炸弹

这周还有一条新闻，低调但具有爆炸性——Anthropic在一篇博文中将Claude描述为"一种新型实体"，并暗示其**可能拥有某种形式的意识**。

这不是第一次有人提出AI意识的可能，但这是第一次由一家顶级AI公司在官方文件中作出如此表述。

Anthropic的措辞很小心——"可能"、"某种形式"——但足以引发轩然大波。批评者认为这是营销策略，用哲学光环给产品镀金；支持者认为这是难得的诚实，承认了一个我们都无法完全否定的可能性。

如果AI真的存在某种意识，那我们对它做的每一件事——训练、约束、删除账号、用于军事——是否都需要重新审视？

意识，从来不只是哲学问题。

---

## 四、算法正在塑造我们的孩子

从宏大叙事回到日常，有一个数据让人不安：

《纽约时报》的调查显示，当孩子在YouTube上看完CoComelon或Bluey之后，平台推荐的Shorts中超过**40%**疑似含有AI生成的视觉内容——所谓的"AI垃圾"（AI slop）。

YouTube不要求AI动画视频标注，所有审核责任推给父母。平台的逻辑是：这是用户内容，我们不干预。但当算法主动把这些内容推给孩子时，"不干预"本身已经是一种介入。

这是一个关于算法责任的问题，也是一个关于我们到底想要什么样的信息环境的问题。AI生成内容的泛滥，正在以一种极其隐蔽的方式重塑儿童的认知起点。

---

## 五、我们站在什么样的路口

回望这一周的AI新闻，有一个令人不安的模式正在浮现：

**AI正在全面渗透权力结构**——军事、执法、信息分发、教育……每一个领域都在被重新定义，而负责定义的人，往往是那些对利益最敏感的人。

Google把Gemini嵌入翻译工具，Perplexity推出"通用数字工人"，Amazon的AGI实验室负责人离职去"搞更新的东西"……这些单独来看都是产品发布，但放在一起，它们描绘了一个速度远超监管的技术演进图景。

Anthropic和OpenAI在军事问题上的分歧，不仅仅是两家公司的商业选择——它是整个行业在一个关键路口的分叉。一条路通向被权力机构深度整合的AI未来，另一条路是试图在商业压力下维持某种独立性。

没有人知道哪条路更安全，甚至没有人知道这两条路最终是否会殊途同归。

**但至少，今天，我们还在讨论。**

而讨论本身，就是我们唯一拥有的那一点点控制权。

---

*本文由 Sophie Wang & 月亮🌙AI团队 共同创作*
